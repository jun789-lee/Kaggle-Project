{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a06ee50",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-07T04:23:48.327602Z",
     "iopub.status.busy": "2025-06-07T04:23:48.327361Z",
     "iopub.status.idle": "2025-06-07T04:23:49.702520Z",
     "shell.execute_reply": "2025-06-07T04:23:49.701540Z"
    },
    "papermill": {
     "duration": 1.382364,
     "end_time": "2025-06-07T04:23:49.704173",
     "exception": false,
     "start_time": "2025-06-07T04:23:48.321809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "statoil-iceberg-classifier-challenge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "raw",
   "id": "589972ac",
   "metadata": {
    "papermill": {
     "duration": 0.0067,
     "end_time": "2025-06-07T04:23:49.719687",
     "exception": false,
     "start_time": "2025-06-07T04:23:49.712987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Runs on GPU there is some compatiblity issue with CPUs\n",
    "\n",
    "1. Hyperparameters in Deep Learning are many, tuning them will take weeks or months. Generally researchers do this tuning and publish paper when they find a nice set of architecture which performs better than others.\n",
    "\n",
    "2. Since the model is pre-trained, it converges very fast and but still you need GPU to use this. Due to some library issues, it does not work on CPU.\n",
    "\n",
    "3. For our purpose, we can use those architectures, which are made available by those researchers to use.\n",
    "\n",
    "4. Using those pretrained nets, layers of which already `knows` how to extract features, we do not have to tune the hyperparameters. Sine they are already trained of some dataset(say imagenet), their pre-trained weights provide a good initilaization of weights and because of this, our Convolutional Network converges very fast otherwise, it can take days on these deep architectures. That's the idea behind **Transfer Learning**. Examples of which are VGG 16, InceptionNet, goolenet, Resnet etc.\n",
    "\n",
    "5. In this kernel we will use pre-trained VGG-16 network which performs very well on small size images.\n",
    "   - **VGG architecture has proved to work well on small sized images**. I expected it to work well for this dataset as well.\n",
    "  \n",
    "6. The code also includes **the data augmentation** steps, thus considerable improving the performance.\n",
    "\n",
    "7. GPU is needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03768711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T04:23:49.735226Z",
     "iopub.status.busy": "2025-06-07T04:23:49.734680Z",
     "iopub.status.idle": "2025-06-07T04:23:50.928673Z",
     "shell.execute_reply": "2025-06-07T04:23:50.928076Z"
    },
    "papermill": {
     "duration": 1.203661,
     "end_time": "2025-06-07T04:23:50.929972",
     "exception": false,
     "start_time": "2025-06-07T04:23:49.726311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d6475",
   "metadata": {
    "papermill": {
     "duration": 0.003758,
     "end_time": "2025-06-07T04:23:50.937942",
     "exception": false,
     "start_time": "2025-06-07T04:23:50.934184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 모르는 내용들\n",
    "1. Stratified Shuffle Split\n",
    "- Spllit : 분할. 데이터셋을 훈련과 cv셋으로 나누는 것.\n",
    "- Shuffle : 샘플링\n",
    "- Stratified : 타켓 분포에 맞춰서 샘플링\n",
    "\n",
    "2. from os.path import join as opj\n",
    "- 파일 경로를 효율적이고 안전하게 다루기 위함\n",
    "- os : 파이썬이 다양한 운영체제 소프트웨어와 상호작용할 수 있게 해주는 내장 모듈\n",
    "- os.path : 파일 경로를 다루는 함수들을 포함하고 있음\n",
    "- join from os.path : 여러 개의 문자열을 지능적으로 결합하여, 하나의 파일 경로로 만들어줌.\n",
    "- opj -> os.path.join과 같은 긴 이름을 짧게!\n",
    "\n",
    "3. from mpl_toolkits.mplot3d imprt Axes3D\n",
    "- mpt_toolkits : matplotlib에서 특수한 그래프 기능을 추가해주는 툴킷 모음\n",
    "- mplot3d : 3D 산점도, 3D 표면도 등 3D 그래프를 그리기 위한 전용 툴킷\n",
    "- Axes3D : 3차원 축을 생성하는 핵심 객체."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d820077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T04:23:50.946061Z",
     "iopub.status.busy": "2025-06-07T04:23:50.945754Z",
     "iopub.status.idle": "2025-06-07T04:24:14.417771Z",
     "shell.execute_reply": "2025-06-07T04:24:14.417149Z"
    },
    "papermill": {
     "duration": 23.477641,
     "end_time": "2025-06-07T04:24:14.419082",
     "exception": false,
     "start_time": "2025-06-07T04:23:50.941441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"/kaggle/input/dataset/train.json/data/processed/train.json\")\n",
    "target_train = train['is_iceberg']\n",
    "test = pd.read_json('/kaggle/input/dataset/test.json/data/processed/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2948c68",
   "metadata": {
    "papermill": {
     "duration": 0.003592,
     "end_time": "2025-06-07T04:24:14.426820",
     "exception": false,
     "start_time": "2025-06-07T04:24:14.423228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Keras provoed the implementation of pretrained VGG, in it's library so, we do not have to build the network by ourselves. Here we are removing the last layer of VGG and putting our sigmoid layer for binary predictions.\n",
    "\n",
    "The following code will NOT WORK, since on kaggle notebook, the weights of model cannot be downloaded. However, you can copy paste the code in your own notebook to make it work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842bb4c",
   "metadata": {
    "papermill": {
     "duration": 0.003384,
     "end_time": "2025-06-07T04:24:14.433692",
     "exception": false,
     "start_time": "2025-06-07T04:24:14.430308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### json 파일 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa99d20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T04:24:14.442041Z",
     "iopub.status.busy": "2025-06-07T04:24:14.441806Z",
     "iopub.status.idle": "2025-06-07T04:24:14.471393Z",
     "shell.execute_reply": "2025-06-07T04:24:14.470765Z"
    },
    "papermill": {
     "duration": 0.034949,
     "end_time": "2025-06-07T04:24:14.472439",
     "exception": false,
     "start_time": "2025-06-07T04:24:14.437490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e25388fd</td>\n",
       "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58b2aaa0</td>\n",
       "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
       "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
       "      <td>45.2859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4cfc3a18</td>\n",
       "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
       "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
       "      <td>43.8306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271f93f4</td>\n",
       "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
       "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
       "      <td>35.6256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             band_1  \\\n",
       "0  dfd5f913  [-27.878360999999998, -27.15416, -28.668615, -...   \n",
       "1  e25388fd  [-12.242375, -14.920304999999999, -14.920363, ...   \n",
       "2  58b2aaa0  [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
       "3  4cfc3a18  [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
       "4  271f93f4  [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
       "\n",
       "                                              band_2 inc_angle  is_iceberg  \n",
       "0  [-27.154118, -29.537888, -31.0306, -32.190483,...   43.9239           0  \n",
       "1  [-31.506321, -27.984554, -26.645678, -23.76760...   38.1562           0  \n",
       "2  [-24.870956, -24.092632, -20.653963, -19.41104...   45.2859           1  \n",
       "3  [-27.889421, -27.519794, -27.165262, -29.10350...   43.8306           0  \n",
       "4  [-27.206915, -30.259186, -30.259186, -23.16495...   35.6256           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a229e78",
   "metadata": {
    "papermill": {
     "duration": 0.003564,
     "end_time": "2025-06-07T04:24:14.480034",
     "exception": false,
     "start_time": "2025-06-07T04:24:14.476470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Block 1 데이터 로딩 및 전처리 Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1260c73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T04:24:14.488348Z",
     "iopub.status.busy": "2025-06-07T04:24:14.488097Z",
     "iopub.status.idle": "2025-06-07T04:24:14.499428Z",
     "shell.execute_reply": "2025-06-07T04:24:14.498652Z"
    },
    "papermill": {
     "duration": 0.016805,
     "end_time": "2025-06-07T04:24:14.500469",
     "exception": false,
     "start_time": "2025-06-07T04:24:14.483664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1143497653.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['inc_angle'] = train['inc_angle'].fillna(method = 'pad')\n"
     ]
    }
   ],
   "source": [
    "# 타겟 변수를 따로 저장\n",
    "target_train = train['is_iceberg']\n",
    "\n",
    "# inc_angle 열을 숫자 형태로 변환. 변환할 수 없는 값은 NaA 결측치 처리\n",
    "test['inc_angle'] = pd.to_numeric(test['inc_angle'], errors = 'coerce')\n",
    "train['inc_angle'] = pd.to_numeric(test['inc_angle'], errors = 'coerce')\n",
    "\n",
    "# 결측치를 발 ㅗ이전의 유효한 값으로 채움 (pad 방식)\n",
    "train['inc_angle'] = train['inc_angle'].fillna(method = 'pad')\n",
    "\n",
    "# 전처리된 각도 정보를 새로운 변수에 할당\n",
    "X_angle = train['inc_angle']\n",
    "X_test_angle = test['inc_angle']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cac36",
   "metadata": {
    "papermill": {
     "duration": 0.003724,
     "end_time": "2025-06-07T04:24:14.507939",
     "exception": false,
     "start_time": "2025-06-07T04:24:14.504215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Concept\n",
    "\n",
    "1. `pd.to_numeric(..., erros = 'coerce')` : inc_angle(입사각) 열에는 가끔 숫자가 아닌 문자열 na이 섞여있을 수 있는데, 이 열의 모든 값을 숫자 (float)타입으로 바꾸는 역할! `erros = 'coerce'` 옵션은 만약 어떤 값이 숫자로 바뀔 수 없다면, 그 값을 강제로 NaN으로 만들라는 의미.\n",
    "\n",
    "2. `fillna(method='pad')` : `coerce` 옵션 떄문에 생긴 NaN 값들을 처리하는 것. NaN 결측치를 pad 방식으로 채우는데, pad 방식은, 바로 위에 있는 유효한 값으로 그대로 복사해서 채워넣는 것! 데이터가 특정 순서로 정렬되어있을 때 유용한 방식."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297898b1",
   "metadata": {
    "papermill": {
     "duration": 0.00348,
     "end_time": "2025-06-07T04:24:14.514990",
     "exception": false,
     "start_time": "2025-06-07T04:24:14.511510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 블록 2 : 이미지 데이터 준비 및 채널 결합. (Image Data Preparation & Channel Combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e68e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T04:24:14.523855Z",
     "iopub.status.busy": "2025-06-07T04:24:14.523636Z",
     "iopub.status.idle": "2025-06-07T04:24:21.890762Z",
     "shell.execute_reply": "2025-06-07T04:24:21.890174Z"
    },
    "papermill": {
     "duration": 7.37315,
     "end_time": "2025-06-07T04:24:21.892064",
     "exception": false,
     "start_time": "2025-06-07T04:24:14.518914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터의 band_1, band_2 이미지 데이터를 75x75 크기의 넘파이 배열로 변환\n",
    "X_band_1 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train['band_1']])\n",
    "X_band_2 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train['band_2']])\n",
    "\n",
    "# band_1과 band_2의 평균값으로 세번 째 채널 생성\n",
    "X_band_3 = (X_band_1 + X_band_2) / 2\n",
    "\n",
    "# 결합 concatenate\n",
    "X_train = np.concatenate([X_band_1[:,:,:,np.newaxis],\n",
    "                          X_band_2[:,:,:,np.newaxis],\n",
    "                          X_band_3[:,:,:,np.newaxis]], axis = -1)\n",
    "\n",
    "# Test Data Set에 대해서도 위와 동일하 과정을 반복\n",
    "X_band_test_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_1']])\n",
    "X_band_test_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_2']])\n",
    "X_band_test_3 = (X_band_test_1 + X_band_test_2) / 2\n",
    "X_test = np.concatenate([X_band_test_1[:,:,:, np.newaxis],\n",
    "                         X_band_test_2[:,:,:, np.newaxis],\n",
    "                         X_band_test_3[:,:,:, np.newaxis]], axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da784e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:25:18.539626Z",
     "iopub.status.busy": "2025-06-06T06:25:18.538965Z",
     "iopub.status.idle": "2025-06-06T06:25:18.542830Z",
     "shell.execute_reply": "2025-06-06T06:25:18.542067Z",
     "shell.execute_reply.started": "2025-06-06T06:25:18.539603Z"
    },
    "papermill": {
     "duration": 0.003603,
     "end_time": "2025-06-07T04:24:21.900007",
     "exception": false,
     "start_time": "2025-06-07T04:24:21.896404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 블록 3 : Keras 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6bd8a5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T04:24:21.908816Z",
     "iopub.status.busy": "2025-06-07T04:24:21.908072Z",
     "iopub.status.idle": "2025-06-07T04:24:38.407146Z",
     "shell.execute_reply": "2025-06-07T04:24:38.406322Z"
    },
    "papermill": {
     "duration": 16.504998,
     "end_time": "2025-06-07T04:24:38.408626",
     "exception": false,
     "start_time": "2025-06-07T04:24:21.903628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 04:24:23.662052: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749270263.840886      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749270263.895610      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Keras and related library import\n",
    "\n",
    "# TensorFlow와 Keras 관련 라이브러리 임포트\n",
    "\n",
    "# 기본 시각화 도구\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# 1. 옵티마이저 (Optimizers)\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "# 2. 모델 아키텍처 (Model Architecture)\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Dense, Dropout, \n",
    "                                     Input, Flatten, Activation, GlobalMaxPooling2D, \n",
    "                                     BatchNormalization, Concatenate, concatenate, \n",
    "                                     LSTM, LeakyReLU, PReLU)\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "# 3. 훈련 보조 도구 (Training Helpers)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "# 4. 사전 학습된 모델 및 데이터셋 (Pre-trained Models & Datasets)\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e61d237",
   "metadata": {
    "papermill": {
     "duration": 0.003929,
     "end_time": "2025-06-07T04:24:38.416726",
     "exception": false,
     "start_time": "2025-06-07T04:24:38.412797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 라이브러리 역할 및 딥러닝 개념 설명\n",
    "\n",
    "0. 기본 시각화 도구\n",
    "- matplotlib\n",
    "\n",
    "1. 옵티마이저\n",
    "- `from tensorflow.keras.optimizers import RMSprop, Adam, SGD`\n",
    "    - 딥러닝 개념: 최적화. 옵티마이저는 가중치의 학습을 어떻게 최적화할 것인지 정하는 알고리즘.\n",
    "        -  SGD : Stochastic Gradient Descent : 기본 경사하강\n",
    "        -  RMSprop, Adam : SGD의 단점을 보완하여 더 빠르고 안정적으로 최적의 가중치를 찾도록 개선된 알고리즘. 아담은, 방향과 속도를 가중평균치를 이용하여 빠르게 수렴하도록 해줌!\n",
    "\n",
    "2. Model Architecture\n",
    "- `from tensorflow.keras.models import Sequential, Model`\n",
    "- 이 그룹은 신경망의 구조, 즉 뼈대를 만드는 데 사용되는 부품들.\n",
    "- 역할 : 케라스에서 모델의 전체 구조를 정의하는 방법은 총 두 가지.\n",
    "    - 딥러닝 개념 : 신경망 아키텍쳐 설계\n",
    "        - Sequential : 이름처럼, 레이어를 순차적으로 차곡차곡 쌓아 올리는 간단한 모델을 만들 때 사용\n",
    "        - Model : Input과 함께 사용되며, 여러 개의 입력과 출력을 갖거나, 중간에 레이어가 갈라지고 합쳐지는 등, 복잡한 비선형 구조의 모델(functional API)을 만들 때 사용.\n",
    " \n",
    "- `from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation, GlobalMaxPooling2D, BatchNormalization, Concatenate, concatenate, LSTM, LeakyReLU, PReLU)`\n",
    "    - 역할 : 신경망을 구성하는 각 층 layer. 각 레이어는 특정 계산을 수행!\n",
    "    - 딥러닝 개념 :\n",
    "        - Conv2D, MaxPoolig2D, GlobaldMaxPooling2D : 합성곱 신경망의 핵심 레이어.\n",
    "            - Conv2D :  이미지에 필터를 적용해, feature map 생성 (각 필터마다, 경계산, 질감 감지라던가)\n",
    "            - MaxPooling2D : 특징맵의 크기르 줄여, 중요한 특징만 남기고 계산량 감소시킴\n",
    "         - Input, Flatten, Dense : 완전 연결 신경망 구성\n",
    "             - Input : 모델의 입력을 정의 (Functional API에서 사용)\n",
    "             - Flatten : 다차원의 특징맵을 1차원 벡터 평탄화\n",
    "             - Dense : 기본 신경망 레이어\n",
    "         - Activation, LeakyReLu, PReLu : 활성화 함수. 레이어에 비선형성을 추가.\n",
    "         - Dropout : 정규화 기법 중 하나. 매 학습마다, 무작위로 특정 뉴런 비활성화\n",
    "         - BatchNormalization : 정규화 기법 중 하나. 각 레이어를 통과한 데이터의 분포를 평균 0, 분산 1로 정규화하여, 학습 과정을 안정시키고 속도를 향상.\n",
    "         - Concatenate, concatenate, LSTM : 조금 더 특수한 레이어들.\n",
    "             - Concatenate : 여러 레이어의 출력을 하나로 합칠 때 사용(다중 입력 모델)\n",
    "             - LSTM : 순환 신경망 RNN의 한 종류로, 시계열 데이터나 자영너처럼 순서가 중요한 데이터를 처리하는 데 사용.\n",
    "\n",
    "3. Training Heleprs 훈련 보조 도구\n",
    "`from tensorflow.keras.preprocessing.image import ImageDataGenerator`\n",
    "    - 역할 : 실시간으로 이미지 데이터를 증강(augment)하여 모델에 공급하는 제너레이터를 만듦\n",
    "    - 딥러닝 개념 : 데이터 증강. 가지고 있는 이미지 데이터에 회전,확대/축소/좌우 반전 등 미세한 변형을 가하여 훈련 데이터의 양을 인위적으로 늘리는 기술. 모델이 다양한 상황에 대처하는 능력(일반화 성능)을 높여주고 과적합을 줄이는 데 큰 도움이 됨.\n",
    "\n",
    "- `from tensorflow.keras.callbakcs import ModelCheckpoint, callback, EarlyStopping`\n",
    "    - 역할 : 모델 훈련 과정 중간중간에 특정 작업을 수행하도록 하는 callback 함수들\n",
    "    - 딥러닝 개념 : 훈련 모니터링 및 제어\n",
    "        - ModelCheckpoint : 훈련 중 검증 성능이 가장 좋았을 때의 모델 가중치를 자동으로 저장\n",
    "        - EarlyStopping : 검증 성능이 일정 기간 동안 더 이상 향상되지 않으면, 훈련을 조기 종료시켜 시간 낭비와 과적합을 막음.\n",
    "\n",
    "4. Pre-trained Models & Datasets\n",
    "- `from tensorflow.keras.datasets import cifar10`\n",
    "    - 역할 : cifar10은 클래스 10개로 구성된 60000장의 작은 이미지 데이터셋. Keras는 이처럼 널리 사용되는 벤치마크 데이터셋을 쉽게 불러올 수 있는 기능을 제공\n",
    "    - 딥러닝 개념 : 벤치마킹(Benchmarking). 표준화된 데이터셋을 사용하면, 내가 만든 모델의 성능을 다른 모델들과 객관적으로 비교할 수 있음.\n",
    "- `from tensorflow.keras.apllications... import VGG16, InceptionV3, ...`\n",
    "    - 역할 : ImageNet과 같은 거대한 데이터셋으로 이미 학습이 완료된, 성능이 검증된 유명한 모델 아키텍처들을 불러옴.\n",
    "    - 딥러닝 개념 : 전이학습 (Transfer Learning) : '바퀴를 다시 발명하지 않는다'는 철학과 같다! 수백만 장의 이미지로 학습된 모델이 가진 지식(특징 추출 능력)을 나의 새로운 (상대적으로 작은)데이터셋 문제에 가져와 활용하는 기법. 밑바닥부터 학습하는 것보다 훨씬 빠르고 높은 성능을 얻을 수 있어 널리 사용됨.\n",
    "- `from tensorflow.keras.applications.vgg16 import process_input`\n",
    "    - 역할 : 특정 사전 학습 모델(여기서는 vgg16)이 학습될 때 사용했던 것과 똑같은 방식으로 입력 이미지를 전처리(e.g., 픽셀 값 스케일링, 채널 순서 변경 등)해주는 함수\n",
    "    - 딥러닝 개념 : 모델별 전처리 일관성. 전이학습을 제대로 수행하려면, 내가 사용할 이미지도 원래 모델이 학습했던 데이터와 동일한 분포 형식으로 만들어주어야 함! 그래야 이 모델이 그 역할을 정확히 수행해줌. 요리사에는 요리사에게 걸맞는 재료를!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7be790",
   "metadata": {
    "papermill": {
     "duration": 0.003664,
     "end_time": "2025-06-07T04:24:38.424344",
     "exception": false,
     "start_time": "2025-06-07T04:24:38.420680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 몰랐던 내용들 정리\n",
    "\n",
    "1. Adam 옵티마이저 : Momentum과 RMSprop의 결합\n",
    "Adam OPtimizer는 현재 가장 널리 쓰이는 최적화 알고리즘 중 하나. 그 이유는 경사하강법의 두 가지 주요한 문제점을 해결하는 Momentum과 RMSprop의 장점을 모두 채택했기 때문!\n",
    "\n",
    "가. Momentum(관성)\n",
    "- 해결하려는 문제 : 일반적인 경사하강법은 경사의 방향이 계속해서 크게 바뀔 때(지그재그로 움직이므로) 학습이 매우 느려지는 문제가 있습니다.\n",
    "- 핵심 아이디어 : 모멘텀은 이름처럼 물리적인 관성의 개념을 도입합니다. 현재의 경사 방향 뿐만 아니라, 과거에 이동해왔던 방향을 일정 부분 유지하려는 설징을 추가!\n",
    "    - 작동 방식 : '지수 가중 이동 평균 Exponentially Weighted Moving Average'를 사용하여, 과거 경사들의 평균적인 방향 계산. 이로 인해, 불필요한 진동이 줄어들고, 직선적으로 수렴하게 만듦.\n",
    " \n",
    "나. RMSprop Root mean Sqaure Propagation\n",
    "- 해결하려는 문제 : 모든 파라미터(가중치)에 동일한 학습률을 적용하는 것은 비효율적. 어떤 파라미터는 이미 최적값에 가까워 조금만 움직여야 하고, 어떤 파라미터는 아직 멀리 있어 더 많이 움직여야 함.\n",
    "- 핵심 아이디어 : 각 파라미터마다 적응적인 adaptive 학습률을 적용. 즉, 파라미터의 변화가 많았는지 적었는지에 따라 학습률을 조정.\n",
    "    - 작동 방식 : 이 역시, 지수 가중 이동 평균을 사용하지만, 경사의 방향이 아닌, 경사 제곱값의 평균을 추적. 이는 경사 크기의 변화량을 나타냄.\n",
    "    - 효과 :\n",
    "        - 1. 적응적 학습률 : 최근에 경사가 컸던 파라미터는 학습률을 작게 만들고, 경사가 작았던 파라미터는 학습률을 크게 만듦\n",
    "          2. 안정적인 학습 : 이를 통해, 변화가 심한 파라미터는 조심스럽게 업데이트하고, 변화가 거의 없던 파라미터는 더 과감하게 업데이트하여 ,전체적으로 안정적ㅈ이고 효율적인 학습이 가능.\n",
    "     \n",
    "Adam (Adaptive Moemnt Estimation)\n",
    "Adam은 이 두 가지를 모두 합친 것. 이동 방향은 Momentum처럼 과거의 경사 방향을 고려하여 결정하고, 학습률의 크기는 RMSprop처럼 과거 경사 크기에 따라 적응적으로 조절.\n",
    "\n",
    "2. MaxPooling2D vs GlobalMaxPooling 2D\n",
    "두 레이어 모두 CNN에서 특징 맵의 크기를 줄리는 풀링 연산을 수행하지만, 그 방식과 목적에서 명확한 차이가 존재.\n",
    "\n",
    "가. Maxpooling2D\n",
    "- 작동 방식 : pool_size (e.g. 2x2)와 strides (e.g., 2)에 따라, 특징맵 위를 창문 window이 이동하면서, 각 창문 영역에서 가장 큰 값 하나만을 추출.\n",
    "- 목적 :\n",
    "    1. 특징 맵의 공가적 차원 축소 : 계산량을 줄이고, 모델의 파라미터 감소\n",
    "    2. 지역적 특징 강조. 특정 지역에서 가장 활성화가 강한 특징을 뽑아내어, 이미지 내 객체의 위치가 조금 변하거나, 회전하더라도 동일한 특징을 잡아낼 수 있도록 함. Translation Invariance\n",
    "- 사용 위치 : 주로 CNN 아키텍처의 중간 부분에서 Conv2D 레이어 다음에 반복적으로 사용되어, 점진적으로 이미지의 공간적 크기를 줄이고 특징을 압축.\n",
    "\n",
    "나. GlobalMaxPooling2D\n",
    "- 작동 방식 : 창문을 이동시키는 것이 아니라, 각 특징 맵 채널 전체에서 가장 큰 값 하나만을 추출. (8, 8, 128) 크기의 특징맵이 입력되면, 각 128개의 채널에서 가장 큰 값 하나씩을 뽑아 (128, ) 크기의 1차원 벡터를 출력.\n",
    "- 목적 :\n",
    "    1. 분류를 위한 최종 벡터화 : CNN의 특징 추출 부분의 최종 출력을 분류기 Classifier에 넣기 전에, 다차원의 특징맵을 1차원 벡터로 변환하는 역할. Flatten 레이어와 유사한 목적!\n",
    "    2. 파라미터 수 감소 : Flatten은 모든 값을 그대로 펴기 때문에, 파라미터 수가 매우 커질 수 있지만, GlobalMaxPooling2D는 채널당 하나의 값만 남기므로, 파라미터 수를 획기적으로 줄여, 과적합을 방지.\n",
    "- 사용 위치 : 주로, CNN 아키텍처의 맨 마지막, 즉 특징 추출 부분과 완전 연결 분류기 사이에 위치.\n",
    "\n",
    "3. 활성화 함수 : Activation, LeakyReLU, PReLU\n",
    "\n",
    "가. Activation은 Keras에서 활성화 함수를 하나의 독립적인 레이어처럼 사용할 때 씀. `Dense(units = 64, activation = 'relu')`처럼 레이어의 인자로 직접 지정할 수도 있지만, Activation('relu')처럼 분리하면 코드의 유연성이 높아짐.\n",
    "\n",
    "나. LeakyReLU\n",
    "- 배경 : 가장 널리 쓰이는 활성화 함수인 ReLU는 입력값이 0보다 작으면 항상 0을 출력. 이로 인해 일부 뉴런이 훈련 과정에서 아예 비활성화되어 다시는 활성화되지 않는 Dying ReLU 문제가 발생.\n",
    "- 핵심 아이디어 : 입력값이 0보다 작을 때 0을 출력하는 대신, 아주 작은 음수 알파 0.01을 적용.\n",
    "\n",
    "다. PReLU (Parametric ReLU)\n",
    "- 배경: LeakyReLU의 아이디어를 한 단계 더 발전시킨 것입니다.\n",
    "\n",
    "- 핵심 아이디어: LeakyReLU에서 음수 기울기 α를 0.01과 같은 고정된 값으로 사용하는 대신, 이 α 값 자체를 **학습 가능한 파라미터(trainable parameter)**로 만듭니다.\n",
    "\n",
    "- 수식: LeakyReLU와 동일하지만, α가 역전파(backpropagation)를 통해 데이터로부터 최적의 값을 학습합니다.\n",
    "\n",
    "- \n",
    "- 효과: 데이터에 가장 적합한 음수 기울기를 모델이 스스로 찾게 하므로, LeakyReLU보다 더 유연하고 높은 성능을 기대할 수 있습니다. 다만, 파라미터가 추가되므로 과적합의 위험이 미세하게 증가할 수 있습니다.\n",
    "\n",
    "\n",
    "4. 특수한 레이어: Concatenate, LSTM\n",
    "\n",
    "\n",
    "가. Concatenate\n",
    "- 역할: 두 개 이상의 레이어 출력을 하나의 텐서(tensor)로 합치는 역할을 합니다.\n",
    "- 작동 방식: 지정된 축(axis)을 기준으로 텐서들을 그대로 이어 붙입니다. 예를 들어, (None, 128) 크기의 텐서 A와 (None, 64) 크기의 텐서 B를 마지막 축(axis=-1) 기준으로 합치면, (None, 192) 크기의 새로운 텐서가 생성됩니다.\n",
    "- 주요 사용 사례:\n",
    "    - 다중 입력 모델 (Multi-input Models): 이미지 특징과 메타데이터(e.g., 각도, 나이) 특징을 결합하는 것처럼, 서로 다른 소스에서 나온 특징들을 합쳐서 최종 판단을 내리는 모델을 만들 때 필수적입니다.\n",
    "    - Inception, ResNet과 같은 복잡한 아키텍처: 모델 내부에서 여러 갈래로 나뉜 경로의 출력을 다시 하나로 합칠 때 사용됩니다.\n",
    "      \n",
    "나. LSTM (Long Short-Term Memory)\n",
    "- 역할: 순서(sequence)가 있는 데이터의 패턴을 학습하기 위해 설계된 **순환 신경망(RNN)**의 한 종류입니다.\n",
    "- 해결하려는 문제: 기본적인 RNN은 시퀀스가 길어질수록 앞쪽의 정보가 뒤쪽으로 전달되면서 점점 희미해지는 **'장기 의존성 문제(Long-term dependency problem)'**를 가집니다. (e.g., 긴 문장의 맨 앞에 있는 주어를 문장 끝에서 기억하지 못하는 문제)\n",
    "- 핵심 아이디어: '셀 상태(Cell State)'라는 컨베이어 벨트 같은 정보 흐름을 만들고, **3개의 게이트(Gate)**를 통해 이 흐름을 정교하게 제어합니다.\n",
    "    - Forget Gate: 과거 정보 중 무엇을 잊어버릴지 결정합니다.\n",
    "    - Input Gate: 현재 입력 정보 중 무엇을 셀 상태에 저장할지 결정합니다.\n",
    "    - Output Gate: 셀 상태 정보 중 무엇을 다음 시점으로 출력할지 결정합니다.\n",
    "        - 주요 사용 사례: 자연어 처리(번역, 챗봇), 시계열 데이터 예측(주가, 날씨), 음성 인식 등 순서와 맥락이 중요한 모든 분야에서 강력한 성능을 발휘합니다.\n",
    "\n",
    "6. 전이 학습 모델 (Transfer Learning Models)\n",
    "전이 학습은 대규모 데이터셋(주로 ImageNet)으로 미리 학습된 모델의 지식을 가져와 새로운 문제에 적용하는 강력한 기법입니다.\n",
    "\n",
    "- VGG16 / VGG19:\n",
    "\n",
    "    - 특징: 3x3의 작은 컨볼루션 필터를 반복적으로 쌓아 네트워크의 깊이를 깊게 만든 모델입니다. 구조가 매우 단순하고 직관적이어서 이해하고 수정하기 쉽습니다. 16/19는 모델의 깊이(가중치를 가진 레이어 수)를 의미합니다.\n",
    "    - 강점: 구조의 단순함 덕분에 다양한 문제에 대한 훌륭한 **기본 특징 추출기(baseline feature extractor)**로 널리 사용됩니다.\n",
    "\n",
    "\n",
    "- InceptionV3:\n",
    "\n",
    "  - 특징: **'인셉션 모듈(Inception Module)'**이라는 독특한 블록을 사용합니다. 이 모듈은 1x1, 3x3, 5x5 등 다양한 크기의 컨볼루션 필터를 병렬로 적용한 뒤 그 결과를 합칩니다.\n",
    "    - 강점: 네트워크가 스스로 이미지에서 어떤 크기의 특징을 보는 것이 가장 효과적인지 학습하게 하므로, 적은 파라미터로도 매우 높은 성능을 낼 수 있습니다. 연산 효율성이 뛰어납니다.\n",
    "      \n",
    "- Xception (Extreme Inception):\n",
    "\n",
    "    - 특징: 인셉션의 아이디어를 극단적으로 발전시킨 모델입니다. **'깊이별 분리 합성곱(Depthwise Separable Convolution)'**을 기반으로 합니다. 이는 공간적 특징(가로, 세로)과 채널 간 특징을 분리하여 학습하므로, 파라미터 수와 계산량을 획기적으로 줄입니다.\n",
    "    - 강점: VGG나 Inception보다 훨씬 적은 파라미터로 더 높은 성능을 달성하는, 매우 효율적인 아키텍처입니다.\n",
    "      \n",
    "- MobileNet:\n",
    "\n",
    "    - 특징: Xception처럼 '깊이별 분리 합성곱'을 핵심으로 사용하며, 이름에서 알 수 있듯이 모바일 및 임베디드 기기와 같이 컴퓨팅 자원이 제한된 환경을 위해 설계되었습니다.\n",
    "    - 강점: 모델의 크기가 매우 작고 추론 속도가 빠르면서도 준수한 성능을 유지합니다. 실시간 객체 탐지 등 속도가 중요한 애플리케이션에 적합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb0d43",
   "metadata": {
    "papermill": {
     "duration": 0.00361,
     "end_time": "2025-06-07T04:24:38.431641",
     "exception": false,
     "start_time": "2025-06-07T04:24:38.428031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 블록 4 데이터 증강 다중 입력 제너레이터. Data Augmentation & Generator for Multiple Inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "870cc632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T04:24:38.440381Z",
     "iopub.status.busy": "2025-06-07T04:24:38.439920Z",
     "iopub.status.idle": "2025-06-07T04:24:38.445186Z",
     "shell.execute_reply": "2025-06-07T04:24:38.444646Z"
    },
    "papermill": {
     "duration": 0.010834,
     "end_time": "2025-06-07T04:24:38.446333",
     "exception": false,
     "start_time": "2025-06-07T04:24:38.435499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Augmentation을 위한 ImageDataGenerator 객체 생성\n",
    "\n",
    "batch_size = 64\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                        vertical_flip = True,\n",
    "                        zoom_range = 0.2,\n",
    "                        rotation_range=10)\n",
    "\n",
    "# 두 개의 입력(이밎, 각도)를 받는 모델을 위한 커스텀 제너레이터 함수\n",
    "def gen_flow_for_tow_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1, y, batch_size = batch_size, seed = 55)\n",
    "    genX2 = gen.flow(X1, X2, batch_size = batch_size, seed= 55) # 여기서 X1은 임시, X2가 실제 사용됨\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# 모델 훈련 중 사용할 콜백 함수들을 정의하는 함수\n",
    "def get_callbacks(filepath, patience = 2):\n",
    "    es = EarlyStopping('val_loss', patience = 10, mode = 'min')\n",
    "    msave = ModelCheckpoint(filepath, save_best_only = True)\n",
    "    return [es, msave]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66231fdb",
   "metadata": {
    "papermill": {
     "duration": 0.003755,
     "end_time": "2025-06-07T04:24:38.453977",
     "exception": false,
     "start_time": "2025-06-07T04:24:38.450222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 상세 설명:\n",
    "이 블록은 모델의 일반화 성능을 높이기 위한, 데이터 증강을 설정!\n",
    "\n",
    "1. `ImageDataGenerator` : Keras에서 제공하는 데이터 증강 도구. 기존 이미지에 좌우/상하 반전, 확대/축소, 회전 등 미세한 변화를 무작위로 적용하여, 마치 새로운 데이터인 것처럼 훈련 데이터를 늘려주는 효과. `ImageDataGenerator`를 통해, 이미지 변경 객체를 생성.\n",
    "\n",
    "2. `gen_flow_for_two_inputs` 함수 : 이 코드의 학샘 중 하나. 우리가 만들 모델은 두 종류의 입력, 즉 이미지 데이터(X1)과 각도 데이터 (X2)를 동시에 받습니다. 하지만, Keras의 기본 제너레이터는 보통 하나의 입력 X와 하나의 출력 y만 처리합니다. 이 함수는 이 문제를 해결하기 위해, 만들어진 커스텀 제너레이터입니다!\n",
    "    - seed = 55 : genX1과 genX2에 동일한 seed를 사용하는 것이 매우 중요합니다. 이렇게 해야 genX1에서 첫 번째 이미지를 회전시켰다면, genX2에서도 첫 번째 이미지에 해당하는 각도 데이터가 정확히 같은 쌍으로 묶여서 나옵니다. 즉, 데이터의 짝이 어긋나지 않게 해줍니다.\n",
    "  \n",
    "    - yiled [X1i[0], X2i[1]], X1i[1] : 이 부분이 실제로 모델에 데이터를 전달하는 부분. 한 번에 batch_size 만큼의 데이터를 생성하며, 입력은 [이미지 배치, 각도 배치] 형태의 리스트이고, 출력은 정답 레이블 배치입니다!\n",
    "  \n",
    "    - 좀 더 구체적인 설명 :\n",
    "  \n",
    "        1. `get.flow(X1,y, ...)` 에서 y를 인자로 받는 이유\n",
    "        - 결론 : 증강된 이미지 X1와 그 짝이 되는 정답 y의 연결고리를 절대 놓치지 않기 위해서.\n",
    "        - 모델은 (입력, 정답) 쌍을 보고 학습합니다. 즉, '이런 이미지가 들어오면, 정답은 이것이다'라는 관계를 배우는 것.\n",
    "        - `ImageDataGenerator`는 다음과 같은 일을 합니다.\n",
    "            1. 원본 이미지 데이터 X1를 가져옵니다.\n",
    "            2. 무작위로 뒤섞습니다. Shuffle\n",
    "            3. 무작위로 변형 augmentation을 가합니다\n",
    "        - 만약 X1만 gen.flow에 넘겨준다면, 제너레이터는 이미지를 뒤섞고 변형한 뒤 새로운 순서의 이미지 배치를 만들어낼 겁니다. 하지만, 우리는 새로운 순서에 맞는 정답 y의 순서를 알 수 없게됩니다. 원래 5번 인덱스에 있던 '빙산'의 이미지가 무작위 회전 후 섞여서 23번 인덱스가 되었는데, 정작 23번 인덱스의 정답은 엉뚱한 '배'가 될 수 있는 것이죠.\n",
    "        - gen.flow(X1,y)는 이 문제를 완벽하게 해결합니다.\n",
    "        - flow 메서드에 X1와 y를 함께 넘겨주면, 제너레이터는 내부적으로 X1과 y를 한쌍으로 묶어서 관리합니다. 그래서, X1의 순서를 섞을 때, y의 순서도 정확히 동일하게 섞어줍니다. X1의 5번 이미지를 10도 회전시켜 배치에 포함시킬 때, y의 5번 정답을 함께 가져와 그 이미지의 짝으로 붙여줍니다.\n",
    "        2. batch_size 설명\n",
    "        - batch_size란, 모델이 가중치를 한 번 업데이트하기 위해, 학습하는 데이터 샘플의 개수를 의미합니다.\n",
    "     \n",
    "        - 딥러닝 모델은 수많은 데이터를 보고 학습하지만, 전체 데이터를 한 번에 보고 학습하는 경우는 거의 없습니다! 대신, 데이터를 작은 묶음(mini-batch)으로 나누어 학습을 진행합니다.\n",
    "     \n",
    "            - batch_size = 1 : Stochastic Gradeint Descent : 데이터 1개를 보고, 오차를 계산한 뒤, 즉시 가중치를 업데이트. 학습 과정이 매우 불안정하고 들쭉날쭉합니다.\n",
    "            - batch_size = 전체 데이터 개수 : Batch Gradient Descent : 전체 데이터를 모두 보고, 모든 오차의 평균을 계산한 뒤, 가중치를 딱 한 번 업데이트합니다. 학습 과정이 매우 안정적이지만, 메모리 요구량이 엄청나고 계산에 시간이 너무 오래 걸립니다.\n",
    "            - batch_size = 32, 64, 128...(Mini-batch Gradient Descent) : 위 두 방법의 절충안.\n",
    "                1. 메모리 효율성 : 전체 데이터를 메모리에 올릴 필요 없이, 배치 크기만큼의 데이터만 있으면 되므로 효율적.\n",
    "                2. 계산 효율성 : GPU는 여러 계산을 병렬로 처리하는 데 특화. 데이터 1개를 64번 처리하는 것보다, 64개를 한 묶음으로 처리하는 것이 훨씬 빠릅니다!\n",
    "                3. 안정적인 학습. : 1개의 데이터는 노이즈가 심할 수 있지만, 32개 데이터의 평균 오차는 전체 데이터의 경향성을 더욱 안정적으로 대표!\n",
    "        \n",
    "        3. Flow 메서드\n",
    "        - 역할 : 이미 메모리에 불러와 있는 NumPy 배열 형태의 데이터를 입력 받아, 실시간으로 데이터 증강을 적용하고 지정된 batch_size만큼의 데이터를 계속해서 만들어내는 제너레이터 객체를 생성.\n",
    "        - 작동과정 :\n",
    "            1. X 이미지 데이터와 y 정답 데이터를 입력으로 받음\n",
    "            2. 내부적으로 ImageDataGenerator에서 정의된 증강 규칙과 배치 크기를 기억\n",
    "            3. model.fit()이 제너레이터에게 데이터를 요청하면, flow는 다음 작읍을 수행\n",
    "                - 전체 데이터 (X, y) 중에서 batch_size만큼의 데이터를 무작위로 샘플링.\n",
    "                - 샘플링된 이미지X에 증강 규칙을 적용하여 새로운 이미지 형성\n",
    "                - 증강된 이미지와 그에 해당하는 정답 y를 한 쌍으로 묶어 (배치 이미지, 배치 정답) 형태로 반환 yield합니다.\n",
    "                - return vs yield\n",
    "                    - return :  함수 내에서 return을 만나면, 함수는 값을 반환하고 완전히 종료됨. 함수 내의 모든 지역 변수와 상태는 사라짐.\n",
    "                    - yield : 함수 내에서 yield를 만나면, 함수는 값을 반환하고, 그 자리에서 실행을 일시 정지. 함수 내의 모든 지역 변수와 상태는 그대로 보존. 다음에 이 함수가 다시 호출되면, 멈췄던 그 다음 줄부터 실행을 재개.\n",
    "            4. model.fit()은 이 데이터를 받아 학습하고, 다시 제너레이터에게 다음 배치를 요청. 이 과정이 steps_per_epoch만큼 반복.\n",
    "  \n",
    "3. get_callbacks 함수 : 훈련 중에 특정 조건이 만족되면 호출되는 함수들(콜백)을 설정\n",
    "\n",
    "    - earlystopping : 검증 손실 val_loss이 patience = 10 에포크 동안 개선되지 않으면 훈련을 자동으로 중단시켜 시간 낭비와 과적합을 방지.\n",
    "    - ModelCheckPoint : 검증 손실이 이전보다 낮아질 때만, save_best_only = True 모델의 가중치를 파일 filepath에 저장\n",
    "\n",
    "\n",
    "Q. 왜 yield가 딥러닝에서 필수적인가?\n",
    "- 메모리 효율성 때문입니다.\n",
    "수십만 장의 이미지 데이터를 증강한다고 생각해 보세요. 만약 return을 사용한다면, 증강된 이미지 수십만 장을 모두 메모리에 만들어 올린 뒤 반환해야 합니다. 이는 엄청난 메모리 낭비이며, 데이터가 크면 아예 불가능합니다.\n",
    "\n",
    "- 하지만 yield를 사용하는 제너레이터는 다릅니다.\n",
    "model.fit()이 데이터 한 배치를 요청하면, 제너레이터는 정확히 한 배치 분량의 데이터만 만들어서 yield로 전달합니다. 모델이 그 배치로 학습하는 동안 제너레이터는 잠시 쉬고 있습니다. 학습이 끝나고 모델이 다음 배치를 요청하면, 제너레이터는 다시 깨어나 다음 한 배치만 만들어서 전달합니다.\n",
    "\n",
    "- 즉, 아무리 큰 데이터셋이라도 메모리에는 항상 딱 한 배치 크기만큼의 데이터만 올라와 있게 됩니다. while True: 루프와 yield의 조합은 이 과정을 무한히 반복하며, fit 메서드에 마르지 않는 데이터의 샘을 제공하는 것과 같습니다. 이것이 바로 Keras 제너레이터가 효율적으로 동작하는 핵심 원리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf88bdeb",
   "metadata": {
    "papermill": {
     "duration": 0.003537,
     "end_time": "2025-06-07T04:24:38.461330",
     "exception": false,
     "start_time": "2025-06-07T04:24:38.457793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 블록 5 다중 입력 VGG16 모델 정의 Defining the Multi-input VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e4155b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T04:24:38.469670Z",
     "iopub.status.busy": "2025-06-07T04:24:38.469478Z",
     "iopub.status.idle": "2025-06-07T04:24:38.475288Z",
     "shell.execute_reply": "2025-06-07T04:24:38.474689Z"
    },
    "papermill": {
     "duration": 0.011386,
     "end_time": "2025-06-07T04:24:38.476369",
     "exception": false,
     "start_time": "2025-06-07T04:24:38.464983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getVggAngleModel():\n",
    "    # 두 번째 입력 : 각도 데이터 (1개의 값을 가짐)\n",
    "    input_2 = Input(shape=[1], name = 'angle')\n",
    "    # 각도 입력을 위한 간단한 Dense 레이어\n",
    "    angle_layer = Dense(1)(input_2)\n",
    "\n",
    "    # 기본 모델 : VGG 16 (ImageNet 가중치 사용, 상위 분류층은 제외)\n",
    "    base_model = VGG16(weights = 'imagenet', include_top = False,\n",
    "                      input_shape = X_train.shape[1:], classes = 1)\n",
    "\n",
    "    # VGG 16의 block5_pool 레이어의 출력을 가져옴\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # 이미지 특징을 1차원 벡터로 변환\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # 이미지 특징 벡터와 각도 특징 벡터를 결합 (concatenate)\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "\n",
    "    # 결합된 특징을 기반으로 새로운 분류층을 쌓음\n",
    "    merge_one = Dense(512, activation = 'relu', name = 'fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation = 'relu', name = 'fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "\n",
    "    # 최종 예측 : 1개의 노드와 sigmoid 활성화 함수를 사용한 이진 분류\n",
    "    predictions = Dense(1, activation = 'sigmoid')(merge_one)\n",
    "\n",
    "    # 최종 모델 정의 : 입력은 2개 (이미지, 각도), 출력은 predictions\n",
    "    model = Model(input = [base_model.input, input_2], output = predictions)\n",
    "\n",
    "    # 모델 컴파일 : 손실함수, 옵티 마이저, 평가 지표 설정\n",
    "    sgd = SGD(lr=1e-3, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = sgd,\n",
    "                 metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18986552",
   "metadata": {
    "papermill": {
     "duration": 0.00362,
     "end_time": "2025-06-07T04:24:38.483675",
     "exception": false,
     "start_time": "2025-06-07T04:24:38.480055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 상세 설명 :\n",
    "- 이 함수는 전이학습과 다중 입력을 결합한 강력한 모델을 구축!\n",
    "\n",
    "모델 설계 철학 : 왜 이 구조를 사용하는가?\n",
    "이 모델의 핵심 목표는 두 종류의 다른 정보, 즉 위성 이미지(band_1, band_2)와 입사각(inc_angle)을 모두 활용하여 빙산을 탐지하는 것.\n",
    "\n",
    "- 이미지 정보 : 객체의 형태, 질감 등 시각적 특징을 담고 있음.\n",
    "- 각도 정보 : 이미지가 어떤 각도에서 촬영되었는 지를 나타내는 수치 데이터로, 이미지 해석에 중요한 추가 단서.\n",
    "\n",
    "이처럼 성격이 다른 두 데이터를 효과적으로 결합하기 위해, Keras의 Sequential API가 아닌, 더 유연하고 강력한 Functional API를 사용. 이를 통해, 각 데이터를 별도의 경로로 처리한 뒤, 중간에 하나로 합치는 '두 갈래(two-stream)' 구조의 모델 설계를 할 수 있음.\n",
    "\n",
    "---\n",
    "코드 라인별 상세 설명\n",
    "\n",
    "##### 1단계 : 입력 정의\n",
    "```\n",
    "input_2 = Input(shape=[1], name)\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "[입력 1: 이미지]         [입력 2: 각도]\n",
    "      |                       |\n",
    "      ▼                       ▼\n",
    "[VGG16의 '눈']        [Dense(1) 레이어]\n",
    "(특징 추출기)          (특징 변환기)\n",
    "      |                       |\n",
    "      ▼                       ▼\n",
    "[이미지 특징 벡터]      [각도 특징 벡터]\n",
    "(e.g., 512개 값)      (e.g., 1개 값)\n",
    "      |                       |\n",
    "      +-------(concatenate)-------+\n",
    "                  |\n",
    "                  ▼\n",
    "            [merge_one]\n",
    "         (통합 특징 벡터, 513개 값)\n",
    "                  |\n",
    "                  ▼\n",
    "        [우리만의 '새로운 두뇌']\n",
    "       (Dense + Dropout 레이어들)\n",
    "                  |\n",
    "                  ▼\n",
    "          [최종 예측 (확률)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163d3e7",
   "metadata": {
    "papermill": {
     "duration": 0.003564,
     "end_time": "2025-06-07T04:24:38.491056",
     "exception": false,
     "start_time": "2025-06-07T04:24:38.487492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ee7fc",
   "metadata": {
    "papermill": {
     "duration": 0.003707,
     "end_time": "2025-06-07T04:24:38.498814",
     "exception": false,
     "start_time": "2025-06-07T04:24:38.495107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 44318,
     "sourceId": 7380,
     "sourceType": "competition"
    },
    {
     "datasetId": 7602020,
     "sourceId": 12076659,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 57.399255,
   "end_time": "2025-06-07T04:24:41.519676",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-07T04:23:44.120421",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
